import requests
import json
import re
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

@dataclass
class ImageSearchQuery:
    """Represents an intelligent image search query generated by LLM"""
    primary_keywords: List[str]
    style_keywords: List[str] 
    mood_keywords: List[str]
    exclude_keywords: List[str]
    orientation: str  # 'landscape', 'portrait', 'squarish'
    color: str  # Actual Unsplash color filter: 'black_and_white', 'black', 'white', 'yellow', 'orange', 'red', 'purple', 'magenta', 'green', 'teal', 'blue'
    order_by: str  # 'relevant' or 'latest'
    
    def to_unsplash_query(self) -> str:
        """Convert to Unsplash API search query"""
        all_keywords = []
        all_keywords.extend(self.primary_keywords[:3])  # Limit primary keywords
        all_keywords.extend(self.style_keywords[:2])    # Limit style keywords
        all_keywords.extend(self.mood_keywords[:2])     # Limit mood keywords
        
        query = ' '.join(all_keywords)
        return query[:100]  # Unsplash has query length limits

class LocalLLMManager:
    """Manages communication with local LLM (LMStudio) for intelligent image selection"""
    
    def __init__(self, base_url: str = "http://localhost:1234", model_name: str = None):
        """
        Initialize LLM manager for LMStudio
        
        Args:
            base_url: LMStudio API endpoint (default: http://localhost:1234)
            model_name: Model name (optional, LMStudio usually auto-detects)
        """
        self.base_url = base_url.rstrip('/')
        self.model_name = model_name
        self.api_url = f"{self.base_url}/v1/chat/completions"
        
    def test_connection(self) -> bool:
        """Test if LMStudio is running and accessible"""
        try:
            response = requests.get(f"{self.base_url}/v1/models", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def generate_image_queries(self, music_analysis: Dict[str, Any]) -> Dict[str, ImageSearchQuery]:
        """
        Generate intelligent image search queries for each music section using LLM
        
        Args:
            music_analysis: Simplified music analysis JSON
            
        Returns:
            Dictionary mapping section keys to ImageSearchQuery objects
        """
        prompt = self._build_analysis_prompt(music_analysis)
        
        try:
            llm_response = self._call_llm(prompt)
            parsed_queries = self._parse_llm_response(llm_response)
            return parsed_queries
        except Exception as e:
            print(f"LLM generation failed: {e}")
            # Fallback to basic queries if LLM fails
            return self._generate_fallback_queries(music_analysis)
    
    def _build_analysis_prompt(self, music_analysis: Dict[str, Any]) -> str:
        """Build prompt for LLM to analyze music and suggest images"""
        
        song_name = music_analysis.get('song', 'Unknown')
        duration = music_analysis.get('duration', 0)
        overall_mood = music_analysis.get('overall_mood', {})
        sections = music_analysis.get('video_sections', [])
        
        prompt = f"""You are an expert creative director for music videos. Your task is to analyze this music and suggest intelligent image search queries for each section.

MUSIC ANALYSIS:
- Song: {song_name}
- Duration: {duration}s
- Overall Energy: {overall_mood.get('energy', 0.5)}
- Overall Vibe: {overall_mood.get('vibe', 'neutral')}
- Tempo: {overall_mood.get('tempo', 120)} BPM
- Key: {overall_mood.get('key', 'C')}

SECTIONS:
"""
        
        for i, section in enumerate(sections):
            prompt += f"""
Section {i+1} ({section.get('start', 0):.1f}s - {section.get('end', 0):.1f}s):
- Type: {section.get('type', 'verse')}
- Energy: {section.get('energy', 0.5)}
- Mood: {section.get('mood', 'neutral')}
- Colors: {', '.join(section.get('colors', []))}
"""

        prompt += """
TASK: For each section, suggest intelligent image search queries that would create a compelling music video. Consider:
1. The emotional journey and energy progression
2. Visual storytelling that matches the music's narrative
3. Aesthetic coherence across sections while allowing for dynamic changes
4. Professional music video visual standards

OUTPUT FORMAT: Respond with ONLY a valid JSON object (no thinking tags, no additional text) in this exact format:

{
  "section_0": {
    "primary_keywords": ["main subject", "setting", "action"],
    "style_keywords": ["photography style", "aesthetic"],
    "mood_keywords": ["emotion", "atmosphere"],
    "exclude_keywords": ["avoid this", "not this"],
    "orientation": "landscape",
    "color": "blue",
    "order_by": "relevant"
  },
  "section_1": {
    "primary_keywords": ["different subject", "new setting", "different action"],
    "style_keywords": ["style", "aesthetic"],
    "mood_keywords": ["emotion", "feeling"],
    "exclude_keywords": ["avoid", "exclude"],
    "orientation": "landscape",
    "color": "green",
    "order_by": "relevant"
  }
}

Remember: 
- Each section should have distinct but coherent visual themes
- Primary keywords should be concrete, searchable terms
- Style keywords should describe photography/visual style
- Mood keywords should enhance the emotional tone
- Exclude keywords help filter out unwanted content
- Orientation should be mostly "landscape" for video backgrounds  
- Color must be one of: black_and_white, black, white, yellow, orange, red, purple, magenta, green, teal, blue
- order_by should be "relevant" (or "latest" for trendy content)

Generate queries for all {len(sections)} sections now:"""

        return prompt
    
    def _call_llm(self, prompt: str) -> str:
        """Call local LLM with the analysis prompt"""
        
        headers = {
            "Content-Type": "application/json"
        }
        
        payload = {
            "messages": [
                {
                    "role": "system", 
                    "content": "You are a creative director specializing in music video imagery. Always respond with valid JSON only, no additional text or thinking tags."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.7,
            "max_tokens": 2000,
            "stream": False
        }
        
        if self.model_name:
            payload["model"] = self.model_name
            
        response = requests.post(
            self.api_url,
            headers=headers,
            json=payload,
            timeout=60
        )
        
        response.raise_for_status()
        result = response.json()
        
        return result['choices'][0]['message']['content']
    
    def _parse_llm_response(self, llm_response: str) -> Dict[str, ImageSearchQuery]:
        """Parse LLM response and convert to ImageSearchQuery objects"""
        
        # Remove thinking tags if present (Qwen thinking model)
        cleaned_response = re.sub(r'<thinking>.*?</thinking>', '', llm_response, flags=re.DOTALL)
        cleaned_response = cleaned_response.strip()
        
        # Find JSON in response (in case there's extra text)
        json_match = re.search(r'\{.*\}', cleaned_response, re.DOTALL)
        if json_match:
            json_text = json_match.group(0)
        else:
            json_text = cleaned_response
        
        try:
            parsed_data = json.loads(json_text)
            
            queries = {}
            for section_key, section_data in parsed_data.items():
                query = ImageSearchQuery(
                    primary_keywords=section_data.get('primary_keywords', []),
                    style_keywords=section_data.get('style_keywords', []),
                    mood_keywords=section_data.get('mood_keywords', []),
                    exclude_keywords=section_data.get('exclude_keywords', []),
                    orientation=section_data.get('orientation', 'landscape'),
                    color=section_data.get('color', 'blue'),
                    order_by=section_data.get('order_by', 'relevant')
                )
                queries[section_key] = query
            
            return queries
            
        except json.JSONDecodeError as e:
            raise Exception(f"Failed to parse LLM response as JSON: {e}\nResponse: {cleaned_response}")
    
    def _generate_fallback_queries(self, music_analysis: Dict[str, Any]) -> Dict[str, ImageSearchQuery]:
        """Generate basic fallback queries if LLM fails"""
        sections = music_analysis.get('video_sections', [])
        queries = {}
        
        for i, section in enumerate(sections):
            section_key = f"section_{i}"
            
            # Basic mapping based on section type and energy
            section_type = section.get('type', 'verse')
            energy = section.get('energy', 0.5)
            colors = section.get('colors', ['neutral'])
            
            if section_type == 'intro':
                primary = ['landscape', 'sunrise', 'horizon']
                style = ['cinematic', 'wide angle']
            elif section_type == 'chorus':
                primary = ['celebration', 'dynamic', 'action']
                style = ['vibrant', 'energetic']
            elif section_type == 'verse':
                primary = ['people', 'lifestyle', 'story']
                style = ['natural', 'authentic']
            elif section_type == 'bridge':
                primary = ['abstract', 'artistic', 'transition']
                style = ['creative', 'unique']
            else:  # outro
                primary = ['sunset', 'peaceful', 'ending']
                style = ['serene', 'calm']
            
            # Adjust mood based on energy
            if energy > 0.7:
                mood = ['energetic', 'dynamic']
            elif energy > 0.4:
                mood = ['balanced', 'moderate']
            else:
                mood = ['calm', 'peaceful']
            
            query = ImageSearchQuery(
                primary_keywords=primary,
                style_keywords=style,
                mood_keywords=mood,
                exclude_keywords=['text', 'logo', 'watermark'],
                orientation='landscape',
                color_preference=colors[0] if colors else 'natural'
            )
            
            queries[section_key] = query
        
        return queries

class EnhancedImageManager:
    """Enhanced image manager with LLM integration"""
    
    def __init__(self, unsplash_manager, llm_manager: LocalLLMManager):
        self.unsplash = unsplash_manager
        self.llm = llm_manager
    
    def search_intelligent_images(self, music_analysis: Dict[str, Any], 
                                 images_per_section: int = 3) -> Dict[str, List]:
        """
        Search for images using LLM-generated intelligent queries
        
        Args:
            music_analysis: Music analysis JSON
            images_per_section: Number of images per section
            
        Returns:
            Dictionary mapping section keys to image lists
        """
        print("Generating intelligent image search queries with LLM...")
        
        # Generate LLM-powered queries
        llm_queries = self.llm.generate_image_queries(music_analysis)
        
        sections_images = {}
        
        for section_key, query in llm_queries.items():
            print(f"Searching images for {section_key} with query: {query.to_unsplash_query()}")
            
            # Search using enhanced query
            images = self.search_with_enhanced_query(query, images_per_section)
            sections_images[section_key] = images
            
            # Rate limiting
            import time
            time.sleep(0.5)
        
        return sections_images
    
    def search_with_enhanced_query(self, query: ImageSearchQuery, count: int) -> List:
        """Search Unsplash with enhanced query parameters (search only, no download)"""
        
        # Build search parameters using proper Unsplash API parameters
        params = {
            'query': query.to_unsplash_query(),
            'per_page': min(count, 30),
            'order_by': query.order_by,
            'content_filter': 'high',
            'orientation': query.orientation,
            'color': query.color  # Direct color parameter from LLM
        }
        
        # Use the existing Unsplash search but with enhanced parameters
        try:
            response = requests.get(
                f"{self.unsplash.base_url}/search/photos",
                headers=self.unsplash.headers,
                params=params,
                timeout=10
            )
            response.raise_for_status()
            
            data = response.json()
            images = []
            
            for photo in data.get('results', []):
                # Filter out images with excluded keywords in description
                description = (photo.get('alt_description', '') or 
                             photo.get('description', '')).lower()
                
                exclude_found = any(keyword.lower() in description 
                                  for keyword in query.exclude_keywords)
                
                if not exclude_found:
                    from image_manager import ImageResult
                    image = ImageResult(
                        id=photo['id'],
                        url=photo['urls']['regular'],
                        download_url=photo['urls']['full'],
                        description=photo.get('alt_description', '') or photo.get('description', ''),
                        photographer=photo['user']['name'],
                        width=photo['width'],
                        height=photo['height'],
                        color=photo.get('color', '#000000')
                    )
                    images.append(image)
            
            return images
            
        except Exception as e:
            print(f"Enhanced search failed: {e}")
            return []

def main():
    """Test LLM integration"""
    
    # Sample music analysis
    sample_analysis = {
        "song": "test_song.mp3",
        "duration": 180.0,
        "overall_mood": {
            "energy": 0.75,
            "vibe": "energetic_happy", 
            "tempo": 128,
            "key": "G"
        },
        "video_sections": [
            {
                "start": 0.0,
                "end": 30.0,
                "type": "intro",
                "energy": 0.3,
                "mood": "calm",
                "colors": ["soft", "light", "peaceful"]
            },
            {
                "start": 30.0,
                "end": 90.0,
                "type": "chorus",
                "energy": 0.9,
                "mood": "high", 
                "colors": ["warm", "bright", "energetic"]
            }
        ]
    }
    
    print("LLM Integration Test")
    print("===================")
    
    # Test LLM connection
    llm_manager = LocalLLMManager()
    
    if not llm_manager.test_connection():
        print("X LMStudio not accessible at http://localhost:1234")
        print("Please start LMStudio and load a model first.")
        return
    
    print("✓ LMStudio connection successful")
    
    try:
        # Generate intelligent queries
        queries = llm_manager.generate_image_queries(sample_analysis)
        
        print("\nLLM-Generated Image Queries:")
        print("=" * 40)
        
        for section_key, query in queries.items():
            print(f"\n{section_key.upper()}:")
            print(f"  Primary: {', '.join(query.primary_keywords)}")
            print(f"  Style: {', '.join(query.style_keywords)}")
            print(f"  Mood: {', '.join(query.mood_keywords)}")
            print(f"  Exclude: {', '.join(query.exclude_keywords)}")
            print(f"  Orientation: {query.orientation}")
            print(f"  Color: {query.color_preference}")
            print(f"  → Unsplash Query: \"{query.to_unsplash_query()}\"")
        
        print(f"\n✓ Successfully generated {len(queries)} intelligent image queries!")
        
    except Exception as e:
        print(f"X Test failed: {e}")

if __name__ == "__main__":
    main()